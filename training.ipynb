{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wT2Bo-lT-UM"
      },
      "source": [
        "# TITLE\n",
        "\n",
        "Authors: Shiva Peri, Hima Gururaj, Nikolas Diamant\n",
        "\n",
        "Code References:\n",
        "[Mesh to SDF](https://github.com/marian42/mesh_to_sdf),\n",
        "[DeepSDF](https://github.com/facebookresearch/DeepSDF),"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rMXSrgKT-UP"
      },
      "source": [
        "#### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use these specific versions so pytorch3d doesnt break\n",
        "\n",
        "!pip install 'torch==1.6.0+cu101' -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install 'torchvision==0.7.0+cu101' -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install 'pytorch3d==0.2.5'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2tU2nkcUPxU",
        "outputId": "57096f21-7228-421f-871b-0c7c7b54a8b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.6.0+cu101 in /usr/local/lib/python3.7/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torchvision==0.7.0+cu101 in /usr/local/lib/python3.7/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0+cu101) (1.21.6)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0+cu101) (1.6.0+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0+cu101) (7.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->torchvision==0.7.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: pytorch3d==0.2.5 in /usr/local/lib/python3.7/dist-packages (0.2.5)\n",
            "Requirement already satisfied: torchvision>=0.4 in /usr/local/lib/python3.7/dist-packages (from pytorch3d==0.2.5) (0.7.0+cu101)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.7/dist-packages (from pytorch3d==0.2.5) (0.1.5.post20220506)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.4->pytorch3d==0.2.5) (1.21.6)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.4->pytorch3d==0.2.5) (1.6.0+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.4->pytorch3d==0.2.5) (7.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->torchvision>=0.4->pytorch3d==0.2.5) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.2.5) (4.64.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.2.5) (0.8.9)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.2.5) (6.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.2.5) (0.1.8)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.2.5) (0.1.9)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.2.5) (1.1.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.7->fvcore->pytorch3d==0.2.5) (2.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oxiZ42B4SwQ-"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions.bernoulli import Bernoulli\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "%matplotlib notebook \n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['savefig.dpi'] = 80\n",
        "mpl.rcParams['figure.dpi'] = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qcdd4ZuDT-UQ"
      },
      "outputs": [],
      "source": [
        "import pytorch3d\n",
        "\n",
        "from pytorch3d.renderer import (\n",
        "    OpenGLPerspectiveCameras,\n",
        "    PointLights,\n",
        "    RasterizationSettings,\n",
        "    TexturesVertex,\n",
        "    look_at_view_transform,\n",
        ")\n",
        "\n",
        "from pytorch3d.structures import Meshes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SFULdhbT-UR",
        "outputId": "c1e3636a-9fd1-492a-8098-8341f7198880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-07 02:50:55--  https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/docs/tutorials/utils/plot_image_grid.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‘plot_image_grid.py’\n",
            "\n",
            "\rplot_image_grid.py    0%[                    ]       0  --.-KB/s               \rplot_image_grid.py  100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-07 02:50:55 (26.9 MB/s) - ‘plot_image_grid.py’ saved [1608/1608]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/docs/tutorials/utils/plot_image_grid.py\n",
        "from plot_image_grid import image_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwpa4Q7BT-UR",
        "outputId": "f18544bd-a51b-4f22-c844-8fbf191e42ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mesh-to-sdf\n",
            "  Downloading mesh_to_sdf-0.0.14-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from mesh-to-sdf) (0.0)\n",
            "Collecting pyrender\n",
            "  Downloading pyrender-0.1.45-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.7/dist-packages (from mesh-to-sdf) (3.1.6)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from mesh-to-sdf) (0.18.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyrender->mesh-to-sdf) (1.21.6)\n",
            "Collecting freetype-py\n",
            "  Downloading freetype_py-2.3.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (978 kB)\n",
            "\u001b[K     |████████████████████████████████| 978 kB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from pyrender->mesh-to-sdf) (2.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pyrender->mesh-to-sdf) (2.6.3)\n",
            "Collecting pyopengl\n",
            "  Downloading PyOpenGL-3.1.0.zip (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pyrender->mesh-to-sdf) (1.15.0)\n",
            "Collecting trimesh\n",
            "  Downloading trimesh-3.12.0-py3-none-any.whl (646 kB)\n",
            "\u001b[K     |████████████████████████████████| 646 kB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyrender->mesh-to-sdf) (1.4.1)\n",
            "Requirement already satisfied: pyglet>=1.4.10 in /usr/local/lib/python3.7/dist-packages (from pyrender->mesh-to-sdf) (1.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pyrender->mesh-to-sdf) (7.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet>=1.4.10->pyrender->mesh-to-sdf) (0.16.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mesh-to-sdf) (2021.11.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mesh-to-sdf) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->mesh-to-sdf) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mesh-to-sdf) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mesh-to-sdf) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mesh-to-sdf) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->mesh-to-sdf) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->mesh-to-sdf) (4.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->mesh-to-sdf) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->mesh-to-sdf) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->mesh-to-sdf) (3.1.0)\n",
            "Building wheels for collected packages: pyopengl\n",
            "  Building wheel for pyopengl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyopengl: filename=PyOpenGL-3.1.0-py3-none-any.whl size=1745210 sha256=554b37e00b7940a502ca4b48d9a87a3312164069e2f175158106608ec3af7e48\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/83/cb/af51a0c06c33d08537b941bbfc87469e8a3c68d05f77a6a212\n",
            "Successfully built pyopengl\n",
            "Installing collected packages: trimesh, pyopengl, freetype-py, pyrender, mesh-to-sdf\n",
            "  Attempting uninstall: pyopengl\n",
            "    Found existing installation: PyOpenGL 3.1.6\n",
            "    Uninstalling PyOpenGL-3.1.6:\n",
            "      Successfully uninstalled PyOpenGL-3.1.6\n",
            "Successfully installed freetype-py-2.3.0 mesh-to-sdf-0.0.14 pyopengl-3.1.0 pyrender-0.1.45 trimesh-3.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mesh-to-sdf\n",
        "\n",
        "from mesh_to_sdf import mesh_to_voxels\n",
        "\n",
        "import trimesh\n",
        "import skimage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbOT0lRWT-US"
      },
      "source": [
        "#### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "x5znxQhLSwRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7034316b-d242-4209-e7e2-43923c04558e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/shivaPeri/16726-final-project/blob/main/data.zip\n",
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "3_A-QEZLiXp6",
        "outputId": "c6f6b805-dc47-4450-a88a-8bbf553e0515",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./data.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of ./data.zip or\n",
            "        ./data.zip.zip, and cannot find ./data.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OZNrJ8XvSwRF"
      },
      "outputs": [],
      "source": [
        "# data loader\n",
        "\n",
        "# TODO\n",
        "class SDFDataLoader(DataLoader):\n",
        "    \n",
        "    def __init__(self, dataset, batch_size, shuffle=True, seq_len=3):\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        pass\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWcMZbFJT-UT"
      },
      "source": [
        "#### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lgTBG5tgT-UU"
      },
      "outputs": [],
      "source": [
        "# Modified DeepSDF decoder from https://github.com/facebookresearch/DeepSDF/blob/main/networks/deep_sdf_decoder.py\n",
        "\n",
        "# TODO: implement Lipschitz regularization\n",
        "class Lipschitz(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Lipschitz, self).__init__()\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        pass\n",
        "\n",
        "\n",
        "# TODO: add Lipschitz to Decoder\n",
        "class DeepSDFDecoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_size,\n",
        "        dims,\n",
        "        dropout=None,\n",
        "        dropout_prob=0.0,\n",
        "        norm_layers=(),\n",
        "        latent_in=(),\n",
        "        weight_norm=False,\n",
        "        xyz_in_all=None,\n",
        "        use_tanh=False,\n",
        "        latent_dropout=False,\n",
        "    ):\n",
        "        super(DeepSDFDecoder, self).__init__()\n",
        "\n",
        "        dims = [latent_size + 3] + dims + [1]\n",
        "\n",
        "        self.num_layers = len(dims)\n",
        "        self.norm_layers = norm_layers\n",
        "        self.latent_in = latent_in\n",
        "        self.latent_dropout = latent_dropout\n",
        "        if self.latent_dropout:\n",
        "            self.lat_dp = nn.Dropout(0.2)\n",
        "\n",
        "        self.xyz_in_all = xyz_in_all\n",
        "        self.weight_norm = weight_norm\n",
        "\n",
        "        for layer in range(0, self.num_layers - 1):\n",
        "            if layer + 1 in latent_in:\n",
        "                out_dim = dims[layer + 1] - dims[0]\n",
        "            else:\n",
        "                out_dim = dims[layer + 1]\n",
        "                if self.xyz_in_all and layer != self.num_layers - 2:\n",
        "                    out_dim -= 3\n",
        "\n",
        "            if weight_norm and layer in self.norm_layers:\n",
        "                setattr(\n",
        "                    self,\n",
        "                    \"lin\" + str(layer),\n",
        "                    nn.utils.weight_norm(nn.Linear(dims[layer], out_dim)),\n",
        "                )\n",
        "            else:\n",
        "                setattr(self, \"lin\" + str(layer), nn.Linear(dims[layer], out_dim))\n",
        "\n",
        "            if (\n",
        "                (not weight_norm)\n",
        "                and self.norm_layers is not None\n",
        "                and layer in self.norm_layers\n",
        "            ):\n",
        "                setattr(self, \"bn\" + str(layer), nn.LayerNorm(out_dim))\n",
        "\n",
        "        self.use_tanh = use_tanh\n",
        "        if use_tanh:\n",
        "            self.tanh = nn.Tanh()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.dropout_prob = dropout_prob\n",
        "        self.dropout = dropout\n",
        "        self.th = nn.Tanh()\n",
        "\n",
        "    # input: N x (L+3)\n",
        "    def forward(self, input):\n",
        "        xyz = input[:, -3:]\n",
        "\n",
        "        if input.shape[1] > 3 and self.latent_dropout:\n",
        "            latent_vecs = input[:, :-3]\n",
        "            latent_vecs = F.dropout(latent_vecs, p=0.2, training=self.training)\n",
        "            x = torch.cat([latent_vecs, xyz], 1)\n",
        "        else:\n",
        "            x = input\n",
        "\n",
        "        for layer in range(0, self.num_layers - 1):\n",
        "            lin = getattr(self, \"lin\" + str(layer))\n",
        "            if layer in self.latent_in:\n",
        "                x = torch.cat([x, input], 1)\n",
        "            elif layer != 0 and self.xyz_in_all:\n",
        "                x = torch.cat([x, xyz], 1)\n",
        "            x = lin(x)\n",
        "            # last layer Tanh\n",
        "            if layer == self.num_layers - 2 and self.use_tanh:\n",
        "                x = self.tanh(x)\n",
        "            if layer < self.num_layers - 2:\n",
        "                if (\n",
        "                    self.norm_layers is not None\n",
        "                    and layer in self.norm_layers\n",
        "                    and not self.weight_norm\n",
        "                ):\n",
        "                    bn = getattr(self, \"bn\" + str(layer))\n",
        "                    x = bn(x)\n",
        "                x = self.relu(x)\n",
        "                if self.dropout is not None and layer in self.dropout:\n",
        "                    x = F.dropout(x, p=self.dropout_prob, training=self.training)\n",
        "\n",
        "        if hasattr(self, \"th\"):\n",
        "            x = self.th(x)\n",
        "\n",
        "        return "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_RXleR9QT-UX"
      },
      "outputs": [],
      "source": [
        "# PointNet feature code from https://github.com/fxia22/pointnet.pytorch/blob/master/pointnet/model.py\n",
        "\n",
        "class STN3d(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(STN3d, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 9)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.bn4 = nn.BatchNorm1d(512)\n",
        "        self.bn5 = nn.BatchNorm1d(256)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "\n",
        "        x = F.relu(self.bn4(self.fc1(x)))\n",
        "        x = F.relu(self.bn5(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        iden = Variable(torch.from_numpy(np.array([1,0,0,0,1,0,0,0,1]).astype(np.float32))).view(1,9).repeat(batchsize,1)\n",
        "        if x.is_cuda:\n",
        "            iden = iden.cuda()\n",
        "        x = x + iden\n",
        "        x = x.view(-1, 3, 3)\n",
        "        return x\n",
        "\n",
        "\n",
        "class STNkd(nn.Module):\n",
        "    def __init__(self, k=64):\n",
        "        super(STNkd, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, k*k)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.bn4 = nn.BatchNorm1d(512)\n",
        "        self.bn5 = nn.BatchNorm1d(256)\n",
        "\n",
        "        self.k = k\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "\n",
        "        x = F.relu(self.bn4(self.fc1(x)))\n",
        "        x = F.relu(self.bn5(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1,self.k*self.k).repeat(batchsize,1)\n",
        "        if x.is_cuda:\n",
        "            iden = iden.cuda()\n",
        "        x = x + iden\n",
        "        x = x.view(-1, self.k, self.k)\n",
        "        return x\n",
        "\n",
        "class PointNetfeat(nn.Module):\n",
        "    def __init__(self, global_feat = True, feature_transform = False):\n",
        "        super(PointNetfeat, self).__init__()\n",
        "        self.stn = STN3d()\n",
        "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.global_feat = global_feat\n",
        "        self.feature_transform = feature_transform\n",
        "        if self.feature_transform:\n",
        "            self.fstn = STNkd(k=64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        n_pts = x.size()[2]\n",
        "        trans = self.stn(x)\n",
        "        x = x.transpose(2, 1)\n",
        "        x = torch.bmm(x, trans)\n",
        "        x = x.transpose(2, 1)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        if self.feature_transform:\n",
        "            trans_feat = self.fstn(x)\n",
        "            x = x.transpose(2,1)\n",
        "            x = torch.bmm(x, trans_feat)\n",
        "            x = x.transpose(2,1)\n",
        "        else:\n",
        "            trans_feat = None\n",
        "\n",
        "        pointfeat = x\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.bn3(self.conv3(x))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "        if self.global_feat:\n",
        "            return x, trans, trans_feat\n",
        "        else:\n",
        "            x = x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
        "            return torch.cat([x, pointfeat], 1), trans, trans_feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Zt-7YsTYSwRI"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "\n",
        "# potentially another architecture to try out\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        pass\n",
        "\n",
        "\n",
        "# from https://arxiv.org/pdf/2202.08345v1.pdf paper\n",
        "class AutoDecoder(nn.Module):\n",
        "    def __init__(self, p=0.5):\n",
        "        super(AutoDecoder, self).__init__()\n",
        "        self.enc = PointNetfeat()\n",
        "        self.dec = DeepSDFDecoder()\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        out = self.enc(inp)\n",
        "        out = self.dec(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMHWmS4UT-UY"
      },
      "source": [
        "#### Training + Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kIvZOIfjSwRK"
      },
      "outputs": [],
      "source": [
        "# model trainer\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, loader, lr=0.1, max_epochs=1, run_id='exp'):\n",
        "        \"\"\"\n",
        "            Use this class to train your model\n",
        "        \"\"\"\n",
        "        # feel free to add any other parameters here\n",
        "        self.model = model\n",
        "        self.loader = loader\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.epochs = 0\n",
        "        self.max_epochs = max_epochs\n",
        "        self.run_id = run_id\n",
        "        \n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        # TODO: try: Dirichlet energy, chamfer loss\n",
        "\n",
        "    # TODO: revisit\n",
        "    def train(self):\n",
        "        self.model.train() # set to training mode\n",
        "        epoch_loss = 0\n",
        "        for batch_num, inp in enumerate(self.loader):\n",
        "            epoch_loss += self.train_batch(inp)\n",
        "        epoch_loss = epoch_loss / (batch_num + 1)\n",
        "        self.epochs += 1\n",
        "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
        "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
        "        self.train_losses.append(epoch_loss)\n",
        "\n",
        "    # TODO: revisit\n",
        "    def train_batch(self, inputs):\n",
        "        \n",
        "        self.optimizer.zero_grad()\n",
        "        outputs, _ = self.model(inputs)\n",
        "        outputs = outputs.permute(0, 2, 1)\n",
        "\n",
        "        # since we are training an autoencoder, the input is the target\n",
        "        loss = self.criterion(outputs, inputs)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        \n",
        "        return loss.item()\n",
        "\n",
        "    \n",
        "    def test(self):\n",
        "        self.model.eval() # set to eval mode\n",
        "        # predictions = TestLanguageModel.prediction(fixtures_pred['inp'], self.model) # get predictions\n",
        "        # self.predictions.append(predictions)\n",
        "        # generated_logits = TestLanguageModel.generation(fixtures_gen, 10, self.model) # generated predictions for 10 words\n",
        "        # generated_logits_test = TestLanguageModel.generation(fixtures_gen_test, 10, self.model)\n",
        "        # nll = test_prediction(predictions, fixtures_pred['out'])\n",
        "        # generated = test_generation(fixtures_gen, generated_logits, vocab)\n",
        "        # generated_test = test_generation(fixtures_gen_test, generated_logits_test, vocab)\n",
        "        # self.val_losses.append(nll)\n",
        "        \n",
        "        # self.generated.append(generated)\n",
        "        # self.generated_test.append(generated_test)\n",
        "        # self.generated_logits.append(generated_logits)\n",
        "        # self.generated_logits_test.append(generated_logits_test)\n",
        "        \n",
        "        # # generate predictions for test data\n",
        "        # predictions_test = TestLanguageModel.prediction(fixtures_pred_test['inp'], self.model) # get predictions\n",
        "        # self.predictions_test.append(predictions_test)\n",
        "            \n",
        "        # print('[VAL]  Epoch [%d/%d]   Loss: %.4f'\n",
        "        #               % (self.epochs, self.max_epochs, nll))\n",
        "        # return nll\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        # don't change these\n",
        "        model_path = os.path.join('experiments', self.run_id, 'model-{}.pkl'.format(self.epochs))\n",
        "        torch.save({'state_dict': self.model.state_dict()},\n",
        "            model_path)\n",
        "        # np.save(os.path.join('experiments', self.run_id, 'predictions-{}.npy'.format(self.epochs)), self.predictions[-1])\n",
        "        # np.save(os.path.join('experiments', self.run_id, 'predictions-test-{}.npy'.format(self.epochs)), self.predictions_test[-1])\n",
        "        # np.save(os.path.join('experiments', self.run_id, 'generated_logits-{}.npy'.format(self.epochs)), self.generated_logits[-1])\n",
        "        # np.save(os.path.join('experiments', self.run_id, 'generated_logits-test-{}.npy'.format(self.epochs)), self.generated_logits_test[-1])\n",
        "        # with open(os.path.join('experiments', self.run_id, 'generated-{}.txt'.format(self.epochs)), 'w') as fw:\n",
        "        #     fw.write(self.generated[-1])\n",
        "        # with open(os.path.join('experiments', self.run_id, 'generated-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
        "        #     fw.write(self.generated_test[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TiUrjbEjSwRQ"
      },
      "outputs": [],
      "source": [
        "# TODO: define other hyperparameters here\n",
        "\n",
        "P = 0.2\n",
        "LR = 0.1\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 256\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DbHH6zXTSwRa",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "c793096f-ee19-4740-c6b1-e0fab03a421d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving models, predictions, and generated words to ./experiments/1651892999\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-bdbb3367130c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# initialize models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSDFDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-7995cc82cc05>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoDecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointNetfeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepSDFDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'latent_size' and 'dims'"
          ]
        }
      ],
      "source": [
        "# generate unique run id\n",
        "run_id = str(int(time.time()))\n",
        "if not os.path.exists('./experiments'):\n",
        "    os.mkdir('./experiments')\n",
        "os.mkdir('./experiments/%s' % run_id)\n",
        "print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)\n",
        "\n",
        "# initialize models\n",
        "model = AutoDecoder()\n",
        "loader = SDFDataLoader(dataset=dataset, batch_size=BATCH_SIZE)\n",
        "trainer = Trainer(model=model, loader=loader, max_epochs=NUM_EPOCHS, run_id=run_id, lr=LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7D8wTJkBSwRc"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "\n",
        "best_nll = 1e30 \n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    trainer.train()\n",
        "    nll = trainer.test()\n",
        "    if nll < best_nll:\n",
        "        best_nll = nll\n",
        "        print(\"Saving model, predictions and generated output for epoch \"+str(epoch+1)+\" with NLL: \"+ str(best_nll))\n",
        "        trainer.save()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2FmDqBCSwRf"
      },
      "outputs": [],
      "source": [
        "# plot training curves\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(1, trainer.epochs + 1), trainer.train_losses, label='Training losses')\n",
        "plt.plot(range(1, trainer.epochs + 1), trainer.val_losses, label='Validation losses')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('NLL')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipdbmqaGSwRh"
      },
      "outputs": [],
      "source": [
        "# see generated output\n",
        "print (trainer.generated[-1]) # get last generated output"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}